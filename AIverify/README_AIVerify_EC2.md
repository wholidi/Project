
# âœ… AI Verify on AWS EC2 â€“ Custom Plugin & Model Testing

This project deploys **[AI Verify](https://aiverify-foundation.github.io/aiverify/)** on an AWS EC2 instance using Docker to evaluate AI/ML models for fairness, explainability, robustness, and compliance. It includes multiple model pipelines, datasets, and test configurations for dynamic plugin execution.

---

## ğŸ›  Deployment Setup

### EC2 Environment
- Instance: Amazon Linux / Ubuntu
- Docker & Docker Compose installed
- Ports: 3000 (web), 6379 (Valkey), 8080 (API Gateway), etc.

### Running Containers
```bash
docker-compose up -d
```
Expected containers:
- `apigw` â€“ API Gateway
- `portal` â€“ Web UI
- `valkey` â€“ Valkey Redis-compatible DB
- `test-engine-worker` â€“ Executes plugins/tests

---

## ğŸ§ª Use Case

The instance runs **custom and sample models** through AI Verify plugins with uploaded configuration files.

Examples include:
- Binary classification (`sample_bc_credit_sklearn_linear`)
- Multi-class classification (`sample_mc_toxic_sklearn_linear`)
- Regression (`sample_reg_donation_sklearn_linear`)
- PyTorch & Sklearn pipelines
- Tabular and image datasets (e.g., fashion MNIST)

---

## ğŸ“ Directory Structure

```
user_defined_files/
â”œâ”€â”€ model/                  # Pre-trained models (.pkl/.sav)
â”œâ”€â”€ data/                   # Test datasets (CSV, images, etc.)
â”œâ”€â”€ pipeline/               # Custom class wrappers & pipelines
â”œâ”€â”€ veritas_data/           # Veritas-specific sample data
â”œâ”€â”€ test_config.json        # Test configuration file
â”œâ”€â”€ final_upload/           # Final package (model + config + data)
â”œâ”€â”€ clean_upload/           # Clean testable bundle
```

---

## ğŸ§ª How to Run a Test

### 1. Upload files via Web Portal or API:
- `model.sav` or `aiverify_model.pkl`
- `test_data.csv` or `.sav`
- `test_config.json`

### 2. Run via API or Portal interface
- Web UI: `http://<EC2-PUBLIC-IP>:3000`
- Or use `curl` to POST model, data, and config

### 3. View results
- Test results show metrics for:
  - **Fairness**
  - **Transparency**
  - **Robustness**
  - **Accountability**

---

## ğŸ“¦ Example Models in Repository

| Model Type     | File / Path                                                             |
|----------------|--------------------------------------------------------------------------|
| Logistic Regression | `model/sample_bc_credit_sklearn_linear.LogisticRegression.sav`     |
| PyTorch Fashion MNIST | `pipeline/sample_fashion_mnist_pytorch/fashion_mnist_pytorch.pt` |
| Multi-Class Toxic    | `pipeline/mc_tabular_toxic/sample_mc_toxic_sklearn_linear.Pipeline.sav` |

---

## ğŸ“¬ Attribution

- ğŸ§ª AI Verify is developed by [AI Verify Foundation](https://aiverifyfoundation.sg/)
- ğŸ“Š This deployment is used to explore AI audit, fairness, and compliance testing
- ğŸ“š Supports integration with EU AI Act, OECD, IMDA Veritas, etc.

---

## âœ… Tips

- ğŸ“ Bundle clean packages under `/final_upload` or `/clean_upload`
- ğŸ§ª Run isolated test sessions with distinct `test_config.json` files
- ğŸ§  Extend by writing your own plugin in `/pipeline/` structure
